{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e658736e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.006345,
     "end_time": "2024-04-18T17:26:23.300017",
     "exception": false,
     "start_time": "2024-04-18T17:26:23.293672",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e019b786",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T17:26:23.313827Z",
     "iopub.status.busy": "2024-04-18T17:26:23.313073Z",
     "iopub.status.idle": "2024-04-18T17:26:23.997807Z",
     "shell.execute_reply": "2024-04-18T17:26:23.996970Z"
    },
    "papermill": {
     "duration": 0.694149,
     "end_time": "2024-04-18T17:26:24.000139",
     "exception": false,
     "start_time": "2024-04-18T17:26:23.305990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "base_folder = '/kaggle/input/bbc-news-summary/BBC News Summary'\n",
    "\n",
    "article_texts = []\n",
    "summaries = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4d8ac8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T17:26:24.013090Z",
     "iopub.status.busy": "2024-04-18T17:26:24.012724Z",
     "iopub.status.idle": "2024-04-18T17:26:44.049754Z",
     "shell.execute_reply": "2024-04-18T17:26:44.048919Z"
    },
    "papermill": {
     "duration": 20.046025,
     "end_time": "2024-04-18T17:26:44.052160",
     "exception": false,
     "start_time": "2024-04-18T17:26:24.006135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for folder_name in os.listdir(os.path.join(base_folder, 'News Articles')):\n",
    "\n",
    "    article_folder = os.path.join(base_folder, 'News Articles', folder_name)\n",
    "    summary_folder = os.path.join(base_folder, 'Summaries', folder_name)\n",
    "\n",
    "    for file_name in os.listdir(article_folder):\n",
    "        article_file = os.path.join(article_folder, file_name)\n",
    "        summary_file = os.path.join(summary_folder, file_name)\n",
    "        \n",
    "        if os.path.exists(article_file) and os.path.exists(summary_file):\n",
    "            try:\n",
    "                article_df = open(article_file, 'r', encoding='utf-8').read()\n",
    "                summary_df = open(summary_file, 'r', encoding='utf-8').read()\n",
    "                \n",
    "                article_texts.append(article_df)\n",
    "                summaries.append(summary_df)\n",
    "            except UnicodeDecodeError:\n",
    "                print(f\"File with incorrect encoding: {article_file}\")\n",
    "                continue\n",
    "\n",
    "data = {'Article Text': article_texts, 'Summary': summaries}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08dfe05f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T17:26:44.065475Z",
     "iopub.status.busy": "2024-04-18T17:26:44.064852Z",
     "iopub.status.idle": "2024-04-18T17:26:44.975198Z",
     "shell.execute_reply": "2024-04-18T17:26:44.973872Z"
    },
    "papermill": {
     "duration": 0.919249,
     "end_time": "2024-04-18T17:26:44.977419",
     "exception": false,
     "start_time": "2024-04-18T17:26:44.058170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data count: 1556\n",
      "Validation data count: 334\n",
      "Test data count: 334\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = df\n",
    "data.columns = ['Article Text', 'Summary']\n",
    "\n",
    "train_data, temp_data = train_test_split(data, test_size=0.3, random_state=42)\n",
    "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
    "\n",
    "train_count = train_data.shape[0]\n",
    "val_count = val_data.shape[0]\n",
    "test_count = test_data.shape[0]\n",
    "\n",
    "print(\"Train data count:\", train_count)\n",
    "print(\"Validation data count:\", val_count)\n",
    "print(\"Test data count:\", test_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ad5a86",
   "metadata": {
    "papermill": {
     "duration": 0.005568,
     "end_time": "2024-04-18T17:26:44.989033",
     "exception": false,
     "start_time": "2024-04-18T17:26:44.983465",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preparing Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95ff7a8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T17:26:45.002110Z",
     "iopub.status.busy": "2024-04-18T17:26:45.001418Z",
     "iopub.status.idle": "2024-04-18T17:28:03.574407Z",
     "shell.execute_reply": "2024-04-18T17:28:03.573389Z"
    },
    "papermill": {
     "duration": 78.581774,
     "end_time": "2024-04-18T17:28:03.576557",
     "exception": false,
     "start_time": "2024-04-18T17:26:44.994783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c76d7dbc2223401db6f7cb69f5e87bfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a058b9f135204ddca4f6a0911db7688b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5.py:220: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a6761e32e454498b166ace26c8c241a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad12904181974c68866aeff9797c8bb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Training Data: 100%|██████████| 1556/1556 [00:09<00:00, 161.31it/s]\n",
      "Processing Validation Data: 100%|██████████| 334/334 [00:02<00:00, 161.95it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
    "\n",
    "def convert_to_features(index, row):\n",
    "    input_encodings = tokenizer(row['Article Text'], truncation=True, padding='max_length', max_length=1024, return_tensors=\"pt\")\n",
    "    target_encodings = tokenizer(row['Summary'], truncation=True, padding='max_length', max_length=512, return_tensors=\"pt\")\n",
    "    \n",
    "    return {\n",
    "        'input_ids': input_encodings['input_ids'],\n",
    "        'labels': target_encodings['input_ids']\n",
    "    }\n",
    "\n",
    "train_features = [convert_to_features(index, row) for index, row in tqdm(train_data.iterrows(), total=len(train_data), desc='Processing Training Data')]\n",
    "val_features = [convert_to_features(index, row) for index, row in tqdm(val_data.iterrows(), total=len(val_data), desc='Processing Validation Data')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34297be7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T17:28:03.609607Z",
     "iopub.status.busy": "2024-04-18T17:28:03.608877Z",
     "iopub.status.idle": "2024-04-18T17:28:03.620448Z",
     "shell.execute_reply": "2024-04-18T17:28:03.619519Z"
    },
    "papermill": {
     "duration": 0.030279,
     "end_time": "2024-04-18T17:28:03.622588",
     "exception": false,
     "start_time": "2024-04-18T17:28:03.592309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4df378",
   "metadata": {
    "papermill": {
     "duration": 0.016347,
     "end_time": "2024-04-18T17:28:03.654646",
     "exception": false,
     "start_time": "2024-04-18T17:28:03.638299",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451847db",
   "metadata": {
    "papermill": {
     "duration": 0.01515,
     "end_time": "2024-04-18T17:28:03.685595",
     "exception": false,
     "start_time": "2024-04-18T17:28:03.670445",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Create a Dataset Class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f5d5618",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T17:28:03.718699Z",
     "iopub.status.busy": "2024-04-18T17:28:03.717910Z",
     "iopub.status.idle": "2024-04-18T17:28:03.724193Z",
     "shell.execute_reply": "2024-04-18T17:28:03.723284Z"
    },
    "papermill": {
     "duration": 0.024931,
     "end_time": "2024-04-18T17:28:03.726365",
     "exception": false,
     "start_time": "2024-04-18T17:28:03.701434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TextSummarizationDataset(Dataset):\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx]\n",
    "\n",
    "train_dataset = TextSummarizationDataset(train_features)\n",
    "val_dataset = TextSummarizationDataset(val_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6799d0ad",
   "metadata": {
    "papermill": {
     "duration": 0.014907,
     "end_time": "2024-04-18T17:28:03.757235",
     "exception": false,
     "start_time": "2024-04-18T17:28:03.742328",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Create Data Loaders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06ac7570",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T17:28:03.790074Z",
     "iopub.status.busy": "2024-04-18T17:28:03.789181Z",
     "iopub.status.idle": "2024-04-18T17:28:03.794097Z",
     "shell.execute_reply": "2024-04-18T17:28:03.793287Z"
    },
    "papermill": {
     "duration": 0.023059,
     "end_time": "2024-04-18T17:28:03.795885",
     "exception": false,
     "start_time": "2024-04-18T17:28:03.772826",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48360263",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T17:28:03.827814Z",
     "iopub.status.busy": "2024-04-18T17:28:03.827517Z",
     "iopub.status.idle": "2024-04-18T17:28:03.873492Z",
     "shell.execute_reply": "2024-04-18T17:28:03.872604Z"
    },
    "papermill": {
     "duration": 0.064992,
     "end_time": "2024-04-18T17:28:03.876106",
     "exception": false,
     "start_time": "2024-04-18T17:28:03.811114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0:\n",
      "{'input_ids': tensor([[[12528,   467, 13288,  ...,     0,     0,     0]]]), 'labels': tensor([[[17716, 12528,  1031,   114,  5190,  6608,    11,  7462,   955,  9428,\n",
      "            130,   182, 11766,    11,   410,     3,     9,  1399,   613,    13,\n",
      "              3, 18147,     8,  1254,    13, 27330,     6,  8936,    11, 27939,\n",
      "             13,     8,   814,  7884,     5,  3713,  2233,  2136,     7,    24,\n",
      "           9437,     6,    11,   116,     8, 12528,  5189,  9567,     7,   190,\n",
      "              6,    34,  4227,   114,     3,     9,  5722,  3125,     5,   634,\n",
      "           9347,    19,    13,   503,    12,   617,     3,     9,  3714,  2164,\n",
      "           3023,    12,     3,     9,     3,  1206,   940,   467,     6,    68,\n",
      "              8,     3, 17398,   914,   405,    59,   129,     8,  5143,     7,\n",
      "          15401,   114,    34,   523,    12,     5,  5680,     8,   467,    19,\n",
      "            207,    44,    19,     3,    15, 17430,    53,    25,    16, 26847,\n",
      "              6,  4896,  8073,    13,  9674, 16856,     5,   448, 12220,  8628,\n",
      "           9650,   165, 17494,    57,  4767,  2549, 12528,  7513,    11, 23613,\n",
      "             12,  5781,   376,   326,   441,  4413,     6, 21248,    15,    26,\n",
      "             57,     3,     9,  3681,    51,  3493,    53, 16352,     5,   196,\n",
      "             17,    19,  2361, 28618,    13,     3,     9,  2136,    13,  3410,\n",
      "             24,     8,   467, 13762,    31,     7,   995,    25,   633,   315,\n",
      "           7749,   966,  2017,    11,  3793,    25,  1224,   139,     3,    52,\n",
      "           5855,  1472, 14466,     7,     3,    18,   150,    97,    19,  1020,\n",
      "             15,    26,    28,     3,     9,  8413,   918,    18,   413,     5,\n",
      "            634,   467,    19,  5676,     6,    59,  1551,    73,  4895,   179,\n",
      "              5,   188,    26, 15766,    53,    24,  6358,  9200,  2233,  6309,\n",
      "            223,  6608,     7,    30,    48,   126,   467,     6,    21,    34,\n",
      "          13288,    12,  2156,    30,     8,  5712,    13,   165,   564,    11,\n",
      "          16562,    12,  3806,     8,   926,    31,     7,  3805,  1254,    13,\n",
      "            694,     5, 23576,    35,   427,    63,    15,    10,   391, 12220,\n",
      "           8628,    19,    91,   230,   279,    63,   623,     8,   167, 16156,\n",
      "           3282,    13,     8,   467,    19,  2492,   625,  3960,     7,   114,\n",
      "            707,   465,     6,  2540,    89,  9963,     6,     3,   547,    18,\n",
      "           8549,   727,  9899,    26, 16899,    11,     3,  2935,   776,    26,\n",
      "           4263,     3,     7,   994, 21168,     3,     4, 18242,   461,     9,\n",
      "           2916,   102,     3,    60,  3042,    52,  7633,   227,    66,   175,\n",
      "            203,     6,    11,    28,    70,  8519, 20518,    16,    46,  4423,\n",
      "            120,  5026, 12905,     7,   179,  2934,     5,  8639,  5651,  2675,\n",
      "             13, 12528,    56,  1077,   253,   631,   270,    12,   143,    34,\n",
      "              3,     9, 20167,  1242,    11,   653,    12,  9751,     8, 12385,\n",
      "              7,     5,  3809,  7081,  2675,     6,     8,  1448,  7100,   427,\n",
      "             63,    15,     3, 17943,     7,  2787,  5655,    59,   163,    13,\n",
      "              8,  2549, 12528, 26327, 19795,    13,  7273,     6,    68,    92,\n",
      "              8,  2431,  4279,    18,    15,    51,    18,   413,    24,     3,\n",
      "          10102,    34,    11,   646,   445,  4389,  2713,     3, 27950,    12,\n",
      "             70,  8990,     7,    21,   186,    46,  1781,     5,     1,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0]]])}\n",
      "Batch 1:\n",
      "{'input_ids': tensor([[[2566,   15, 2565,  ...,    0,    0,    0]]]), 'labels': tensor([[[ 4452,   210,  1171,    31,     7,  1486,  6585,  2139,   896,   369,\n",
      "            223,    45,   192,  1766,   323,    12,     3, 11005,   524,     3,\n",
      "              9,  8417,  1369,    44,   205,  6770,  2409,    11,  2566,    15,\n",
      "           2565, 17024,   189,  3375,    28, 30894,  7930,  2504,  1803, 16990,\n",
      "           6029, 15627,   535,  3845,    19,   341,     3,     9,   463,  1959,\n",
      "             11,  4054,   213,     8,  3134,    19,     3,    18,    62,    43,\n",
      "            131,   530,    12,  1899,   376,    28, 28957,    11,     6,    16,\n",
      "              8,   414,     6,    62,   410,   976,  2566,    15,  2565,   243,\n",
      "              5,  7296, 13263,   896,  7930,  8595,  2566,    15,  2565,    65,\n",
      "              3, 24266,  6585,    52,  5376,  4232,  4452,   210,  1171,    21,\n",
      "            112, 15754,  1205,    12,   607,     5,   634,  1798, 15131,  6585,\n",
      "             52,     6,   113,  2301,    12,   896,    16,  3888,   227,     3,\n",
      "              9,  2714, 28388,    44, 23370,     6,    65,  3392,    26,   223,\n",
      "            139,   166,    18, 11650, 29205,   227,  8335,    28,  4639,    44,\n",
      "              8,   456,    13,     8,   774,   535,  3845,    65,  1279,   614,\n",
      "             12,   129,   223,    12,   213,     3,    88,    19,   230,   535,\n",
      "            634,  2838,    18,  1201,    18,  1490,     6,    91,    13, 14499,\n",
      "             44,   896,  2283,    48,   774,     6,   808,   112,  6552,  2009,\n",
      "           1288,     3,    17,  1427,   657,  4261,    28,     3,     9,  3858,\n",
      "            565,    16,  2089,    31,     7,     3, 21160,  1369,    44, 30894,\n",
      "              5,     1,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0]]])}\n",
      "Batch 2:\n",
      "{'input_ids': tensor([[[14717,     7,  9116,  ...,     0,     0,     0]]]), 'labels': tensor([[[ 7107,    16,   707,   419,  8155,    31,     7,  8165,     7,   268,\n",
      "           4728,  4848,  6370,    12,   668,  3539,    51, 24617,    15,     7,\n",
      "              5, 23057,  7085,    44,  2557,  2672,  8337,   707,   419,  8155,\n",
      "             31,     7,  4728,   668,  5170,    38,   585,  1358,  4659,    11,\n",
      "           1085,  5692,  5402,     5, 14561,   419,  8155,    31,     7,    65,\n",
      "           1192,   165,  4948,    30,  5874,  8165,  5204,    13,   600,    18,\n",
      "           4350, 14106,   494,     5,   634,  1669,   243,   165,  9613,   130,\n",
      "           1283,    51, 24617,    15,     7,  8785,  4729,  5898,   117,  3996,\n",
      "           3707, 14835,    61,    21,     8,   386,   767,    12,  1882,    30,\n",
      "           1085,    84,  4728,     3,  5953,    12,     3, 25211,   115,    29,\n",
      "          24617,    15,     7,     5, 14561,   419,  8155,    31,     7,  2557,\n",
      "           9216,    33,  7241,  2793,  2199,    79,   396,   522,  2437,  3265,\n",
      "           1666,     7,     5,     1,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0]]])}\n",
      "Batch 3:\n",
      "{'input_ids': tensor([[[26002,     3,    31,  ...,     0,     0,     0]]]), 'labels': tensor([[[  707,   272, 12775,    29,   243,    24,   151,    92,   261,    70,\n",
      "           1861,  7219,    16,   182,   315,  1155,    12,   814,    11,   237,\n",
      "           1125,  7724,     5,  7825,  3258,     6,     3,    88,   243,     6,\n",
      "            230,     3, 27516,    13,     8,  4318,   151,  6964,     7,   739,\n",
      "              3, 21360,   169,    70,  1861,   951,    44,   709,   728,     3,\n",
      "              9,   847,     5, 14561,   272, 12775,    29,   243,    24,   778,\n",
      "           2279,    13,  1861,   951,  4742,    16,  3411,  3776,    12,     3,\n",
      "          18531,    24,     8,  4337,    47,   352,    12,    36,     3,     9,\n",
      "              3, 23588,     5, 14561,   272, 12775,    29,   243,    24,  2199,\n",
      "           3674,   103,   125,    79,   373,   410,    68,   169,     3,     9,\n",
      "            951,    12,   103,    34,     6,     8, 17224,  1196,    13,   125,\n",
      "              8,   126, 26331,  2896,   143,   487,   405, 11556,  1262,   126,\n",
      "           8966,    11,  4026,     7,     5,  3809,     8,   810,     6,  6964,\n",
      "              7,   739, 19257,   209, 13161,  1156,   951,  2713,    30,     8,\n",
      "           1155,    79,   169,    70,   951,     5, 14561,   272, 12775,    29,\n",
      "            243,  1637,     3,    26, 17344,    96, 12364,    15,   277,   121,\n",
      "             11,    96, 11303,   343,     7,   121,   130,   167,  1638,    16,\n",
      "           1119,   126,   378,    11,   130,  1187,     8,   456,    13,   186,\n",
      "           5001,    16,   951,   169,     5,   279,    63,  4656,     6,     3,\n",
      "             88,   243,     6,  1861,  7219,   130,   271,   261,   231,    72,\n",
      "             12,  4105,     3,     9,   798,    11,   130,   271,     3, 16846,\n",
      "            139,  4604,   280,     5, 27674,  1227,  5414,    43,   373,   118,\n",
      "           1012,     6,     3,     9,  1156,   951,  1636,   902,    80,  5005,\n",
      "             28,     3,     9,  1861,  1636,  1691,   135,   453,    34,    16,\n",
      "              3,     9,   315,   607,   535, 31806,    16,     8,   681,   132,\n",
      "             65,   118,   396,   231,   992,    30,   338,   748,   976,   243,\n",
      "            707,  2457,   272, 12775,    29,     6,  2991,  8815,    30,  1156,\n",
      "            783,    44,  6964,     7,   739,    31,     7,  3733,    11,  5399,\n",
      "           7690,     5,   188,    29,  9269,  2945,     3, 19585,     8,  1634,\n",
      "             13,   483,    16,  1156,   951,   169,    47,     8,   650,  1634,\n",
      "             28,    84,   126,  1904,    33,  2944,    57, 11200,     7,    11,\n",
      "           1037,   343,     7,     5, 10723,   207,   677,    13,    48,    47,\n",
      "          25933,    18,  9933,   859,  5868,   151,     6,     3,    88,   243,\n",
      "            535, 10273,   131,   888,     8,  1756,   139,     8,  1156,   951,\n",
      "             38,    34,    31,     7,     3,     9,   231,    72,  4979,   194,\n",
      "             12,   103,    34,   535,   121, 24337,    31,     7,  8966,  2367,\n",
      "              8,   337,   976,   243,   707,   272, 12775,    29,     5,     1,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0]]])}\n",
      "Batch 4:\n",
      "{'input_ids': tensor([[[9864, 1483, 6722,  ...,    0,    0,    0]]]), 'labels': tensor([[[  299,  1321,  3644,     8,   475,  2799,    16,     8,  1569,    56,\n",
      "             59,   217,  1933,    13,  1363,  9864,  1483,    68,    56,    43,\n",
      "             70,  1218,    16,    89,  7633,    57,     3,     9,  6722,     5,\n",
      "            634,  1450,   866,    13,  1046,    16,  1363,  9864,  1483,    11,\n",
      "            112,  1045,   280,    11,     8,   508,   381,    13,  4175,  1694,\n",
      "             12,  3071,  1637,    30,     8,  3134,   429,  1243,    24,     8,\n",
      "          22326,   478,     3, 23386,     3,     9,   418,    13,   151,    91,\n",
      "              5,   634,  3179,    13,     8,  9864,  1483,  1758, 10968,  7066,\n",
      "             19,   131,   430,   677,    16,     3,     9,   307,   689,    13,\n",
      "          19601,    24,  1668,    30,  1046,    16, 20076,    16,    46,  3332,\n",
      "             12,  2914,    70,  3060,     5, 27837,  5943,    33,  3415,    30,\n",
      "           1046,    16,  1955,  9864,  1483,    12, 10973,    70, 22326,     3,\n",
      "           3404,     7,     5,   634,   478,    24,  2438,     7,  1402,    19,\n",
      "            718,     8, 12715,  6768,    63, 10968,  7066,    11,    34,     3,\n",
      "           9000,    12, 11474,  2104,     7,   139,    78,    18,  9341,     3,\n",
      "             31,  4045,  5275,    24,    33,   557,   261,    12, 10973, 13655,\n",
      "           4842,  4175,    42,    12,  3289,  6032,   640,     8,   765,     5,\n",
      "            634,   399,  2532,  2936,   478,  9540,     3,     9,   223, 11968,\n",
      "             30,     3,     9,  1218,    78,    34,    54,    36,  6478, 20081,\n",
      "             57, 22326, 24041,     5,     1,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0]]])}\n"
     ]
    }
   ],
   "source": [
    "for idx, batch in enumerate(train_dataloader):\n",
    "    print(f\"Batch {idx}:\")\n",
    "    print(batch)\n",
    "    if idx > 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e22477",
   "metadata": {
    "papermill": {
     "duration": 0.015346,
     "end_time": "2024-04-18T17:28:03.908062",
     "exception": false,
     "start_time": "2024-04-18T17:28:03.892716",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Set Up Training Loop:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31fdbefd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T17:28:03.940751Z",
     "iopub.status.busy": "2024-04-18T17:28:03.940422Z",
     "iopub.status.idle": "2024-04-18T20:17:31.674091Z",
     "shell.execute_reply": "2024-04-18T20:17:31.672969Z"
    },
    "papermill": {
     "duration": 10167.753011,
     "end_time": "2024-04-18T20:17:31.676617",
     "exception": false,
     "start_time": "2024-04-18T17:28:03.923606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████| 1556/1556 [07:57<00:00,  3.26it/s]\n",
      "Validation Epoch 1: 100%|██████████| 334/334 [00:30<00:00, 10.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 0.18104116259032627, Validation Loss: 0.10223920538207282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████| 1556/1556 [07:57<00:00,  3.26it/s]\n",
      "Validation Epoch 2: 100%|██████████| 334/334 [00:30<00:00, 10.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Training Loss: 0.11550749267587931, Validation Loss: 0.09881793623957448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████| 1556/1556 [07:57<00:00,  3.26it/s]\n",
      "Validation Epoch 3: 100%|██████████| 334/334 [00:30<00:00, 10.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Training Loss: 0.10000800559713785, Validation Loss: 0.10124160113750015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████| 1556/1556 [07:57<00:00,  3.26it/s]\n",
      "Validation Epoch 4: 100%|██████████| 334/334 [00:30<00:00, 10.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Training Loss: 0.09043314843154261, Validation Loss: 0.100906733377463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|██████████| 1556/1556 [07:57<00:00,  3.26it/s]\n",
      "Validation Epoch 5: 100%|██████████| 334/334 [00:30<00:00, 10.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Training Loss: 0.07575574906253804, Validation Loss: 0.10444623536937786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6: 100%|██████████| 1556/1556 [07:57<00:00,  3.26it/s]\n",
      "Validation Epoch 6: 100%|██████████| 334/334 [00:30<00:00, 10.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Training Loss: 0.06697620540841753, Validation Loss: 0.10830523139061016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7: 100%|██████████| 1556/1556 [07:57<00:00,  3.26it/s]\n",
      "Validation Epoch 7: 100%|██████████| 334/334 [00:30<00:00, 10.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Training Loss: 0.05907870677855239, Validation Loss: 0.11134369678594573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8: 100%|██████████| 1556/1556 [07:57<00:00,  3.26it/s]\n",
      "Validation Epoch 8: 100%|██████████| 334/334 [00:30<00:00, 10.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Training Loss: 0.0553179509372296, Validation Loss: 0.10860263129618175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9: 100%|██████████| 1556/1556 [07:57<00:00,  3.26it/s]\n",
      "Validation Epoch 9: 100%|██████████| 334/334 [00:30<00:00, 10.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Training Loss: 0.047281200996334344, Validation Loss: 0.11689257234109086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10: 100%|██████████| 1556/1556 [07:57<00:00,  3.26it/s]\n",
      "Validation Epoch 10: 100%|██████████| 334/334 [00:30<00:00, 10.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Training Loss: 0.04072276950792283, Validation Loss: 0.11560804796339609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11: 100%|██████████| 1556/1556 [07:57<00:00,  3.26it/s]\n",
      "Validation Epoch 11: 100%|██████████| 334/334 [00:30<00:00, 10.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Training Loss: 0.03893251708250973, Validation Loss: 0.12559958647805528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12: 100%|██████████| 1556/1556 [07:57<00:00,  3.26it/s]\n",
      "Validation Epoch 12: 100%|██████████| 334/334 [00:30<00:00, 10.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Training Loss: 0.03588726652285161, Validation Loss: 0.12705536797561845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13: 100%|██████████| 1556/1556 [07:57<00:00,  3.26it/s]\n",
      "Validation Epoch 13: 100%|██████████| 334/334 [00:30<00:00, 10.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Training Loss: 0.030174349281747746, Validation Loss: 0.1264774601193407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14: 100%|██████████| 1556/1556 [07:57<00:00,  3.26it/s]\n",
      "Validation Epoch 14: 100%|██████████| 334/334 [00:30<00:00, 10.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Training Loss: 0.02714253457974136, Validation Loss: 0.12480318584565832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15: 100%|██████████| 1556/1556 [07:58<00:00,  3.25it/s]\n",
      "Validation Epoch 15: 100%|██████████| 334/334 [00:30<00:00, 10.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Training Loss: 0.02531093106631663, Validation Loss: 0.13243456644774276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16: 100%|██████████| 1556/1556 [07:58<00:00,  3.25it/s]\n",
      "Validation Epoch 16: 100%|██████████| 334/334 [00:30<00:00, 10.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Training Loss: 0.02807855675715066, Validation Loss: 0.14028386377043184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17: 100%|██████████| 1556/1556 [07:57<00:00,  3.26it/s]\n",
      "Validation Epoch 17: 100%|██████████| 334/334 [00:30<00:00, 10.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Training Loss: 0.01943401976729142, Validation Loss: 0.1431833399279084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18: 100%|██████████| 1556/1556 [07:57<00:00,  3.26it/s]\n",
      "Validation Epoch 18: 100%|██████████| 334/334 [00:30<00:00, 10.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Training Loss: 0.01993153448622537, Validation Loss: 0.1431729905032375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19: 100%|██████████| 1556/1556 [07:58<00:00,  3.25it/s]\n",
      "Validation Epoch 19: 100%|██████████| 334/334 [00:30<00:00, 10.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Training Loss: 0.017543688958521157, Validation Loss: 0.142804924091197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20: 100%|██████████| 1556/1556 [07:57<00:00,  3.26it/s]\n",
      "Validation Epoch 20: 100%|██████████| 334/334 [00:30<00:00, 10.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Training Loss: 0.015772049136231897, Validation Loss: 0.1494130449852769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    for batch in tqdm(train_dataloader, desc=f'Training Epoch {epoch + 1}'):\n",
    "        optimizer.zero_grad()\n",
    "        inputs = batch['input_ids'].squeeze(dim=1).to(device)\n",
    "        labels = batch['labels'].squeeze(dim=1).to(device)\n",
    "        outputs = model(input_ids=inputs, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_dataloader, desc=f'Validation Epoch {epoch + 1}'):\n",
    "            inputs = batch['input_ids'].squeeze(dim=1).to(device)\n",
    "            labels = batch['labels'].squeeze(dim=1).to(device)\n",
    "            outputs = model(input_ids=inputs, labels=labels)\n",
    "            total_val_loss += outputs.loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch + 1}, Training Loss: {total_train_loss / len(train_dataloader)}, Validation Loss: {total_val_loss / len(val_dataloader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4dd1a98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T20:17:37.173730Z",
     "iopub.status.busy": "2024-04-18T20:17:37.173215Z",
     "iopub.status.idle": "2024-04-18T20:17:38.340173Z",
     "shell.execute_reply": "2024-04-18T20:17:38.339299Z"
    },
    "papermill": {
     "duration": 3.949758,
     "end_time": "2024-04-18T20:17:38.342309",
     "exception": false,
     "start_time": "2024-04-18T20:17:34.392551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Model-Files/tokenizer_config.json',\n",
       " 'Model-Files/special_tokens_map.json',\n",
       " 'Model-Files/spiece.model',\n",
       " 'Model-Files/added_tokens.json')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained('Model-Files')\n",
    "tokenizer.save_pretrained('Model-Files')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572e5e5b",
   "metadata": {
    "papermill": {
     "duration": 2.707203,
     "end_time": "2024-04-18T20:17:43.620046",
     "exception": false,
     "start_time": "2024-04-18T20:17:40.912843",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Test on a new summary here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "534ee635",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T20:17:55.798089Z",
     "iopub.status.busy": "2024-04-18T20:17:55.797738Z",
     "iopub.status.idle": "2024-04-18T20:18:04.657548Z",
     "shell.execute_reply": "2024-04-18T20:18:04.656380Z"
    },
    "papermill": {
     "duration": 11.456698,
     "end_time": "2024-04-18T20:18:04.659789",
     "exception": false,
     "start_time": "2024-04-18T20:17:53.203091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "While these techniques were able to compute a sound summary by key phrase extraction, all of them were extractive approaches and were simply trimming the original text.1.2 Summarization Techniques Text summarisation can be broadly classified into two approaches [2] - Extractive SumMarization [3[], if summary from the given text is created by selecting o subset of the total sentence base.It transforms the text by paraphrasing sections of this original document.Writer Dudley Nichols refused his Academy Award in 1935, creating the encoder-decoder model [9].A shorter text or summary would provide more significant insights.Analyst comparison, we have used the BBC news dataset that contains text data that can been used for summariization and human generated summaries for evaluating and comparing the sumesian Learning Models as was done in the paper [6].]This work will focus on abstractive sumarization to create an accurate and fluent summary as this task is more challenging and simulates human perception for developing summataries.While these technologies were the resulting text, hence making it more complicated.This methodology of LSTM network[9] was utilized to develop the coder and decodingr style [8].The extraction technique identifies an relevant sentences from their original sentence and extracts only those from that text.But there was still the issue of parallelization.Ceanwhile, computing text summerization techniques, the summary is generated after interpreting the initial text (thereby making things more accessible.Accessoseq models implemented with the help of an encodeer-descoded framework for solving NLP tasks gave wonderful results, but there wasn still an issue in that sentence.In this paper, We will be examining why and how machine learning techniques are employed for the task of sumMarisation.Sequeval, data are not much\n"
     ]
    }
   ],
   "source": [
    "def summarize(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=1024, truncation=True).to(device)\n",
    "    summary_ids = model.generate(\n",
    "    inputs['input_ids'], \n",
    "    max_length=1024, \n",
    "    num_beams=4, \n",
    "    length_penalty=2.0, \n",
    "    early_stopping=True, \n",
    "    no_repeat_ngram_size=2\n",
    ").to(device)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "article= '''Abstract. The amount of text data available online is increasing at a very fast pace hence text summarization has become essential. Most of the modern \n",
    "recommender and text classification systems require going through a huge \n",
    "amount of data. Manually generating precise and fluent summaries of lengthy \n",
    "articles is a very tiresome and time-consuming task. Hence generating automated \n",
    "summaries for the data and using it to train machine learning models will make \n",
    "these models space and time-efficient. Extractive summarization and abstractive \n",
    "summarization are two separate methods of generating summaries. The extractive \n",
    "technique identifies the relevant sentences from the original document and \n",
    "extracts only those from the text. Whereas in abstractive summarization \n",
    "techniques, the summary is generated after interpreting the original text, hence \n",
    "making it more complicated. In this paper, we will be presenting a comprehensive \n",
    "comparison of a few transformer architecture based pre-trained models for text \n",
    "summarization. For analysis and comparison, we have used the BBC news dataset \n",
    "that contains text data that can be used for summarization and human generated \n",
    "summaries for evaluating and comparing the summaries generated by machine \n",
    "learning models. \n",
    "Keywords: Natural Language Processing, Deep Learning, Summarization, \n",
    "Transformers  \n",
    "1   Introduction \n",
    "The aim of news summarization is to create a concise summary from a long document \n",
    "or news articles such that no information is lost. In recent times, computing text \n",
    "summaries using Deep Learning has gained popularity \n",
    "1.1   Need for Text Summarization \n",
    "Automating summarization [1] would eliminate manual efforts. Shorter texts, which \n",
    "are summaries of longer texts, would reduce reading time. With the ever-growing \n",
    "amount of data, text summarization would reduce the size of files and hence solve the \n",
    "problem of storage. A shorter text or summary would provide more significant insights. \n",
    "Moreover, accurate summaries are very useful when it comes to text mining and data \n",
    "analysis. \n",
    "1.2   Summarization Techniques \n",
    "Text summarization can be broadly classified into two approaches [2] -  \n",
    "Extractive Summarization - In extractive summarization [3[], a summary from the \n",
    "given text is created by selecting a subset of the total sentence base. Most important \n",
    "phrases or sentences from the text are identified and selected based on a score that is \n",
    "computed depending on the words in that sentence. \n",
    "Abstractive Summarization - In the method of abstractive summarization [4], an \n",
    "interpretation is first created by analysing the text document. Based on this \n",
    "interpretation, the machine predicts a summary. It transforms the text by paraphrasing \n",
    "sections of the original document. \n",
    "This work will focus on abstractive summarization to create an accurate and fluent \n",
    "summary as this task is more challenging and simulates human perception for \n",
    "developing summaries. For this task, we have used some machine learning models pre\n",
    "trained on a large dataset. \n",
    "2   Related Work \n",
    "The task of summarization using NLP first came into the picture in 1958. Initially, \n",
    "statistical approaches were used to compute a score for every sentence and then select \n",
    "the sentences with the highest scores. Several techniques were employed to calculate \n",
    "this score, such as TF-IDF [5], Bayesian models [6], etc. While these techniques were \n",
    "able to compute a sound summary by key phrase extraction, all of them were extractive \n",
    "approaches and were simply trimming the original text. Then the focus came onto \n",
    "utilizing Machine learning algorithms [1] for summarization, such as Bayesian \n",
    "Learning Models as was done in the paper [6]. These machine learning techniques \n",
    "proved to be successful for pattern recognition in texts and establishing a correlation \n",
    "between different words. In this section, we will be examining why and how machine \n",
    "learning techniques were employed for the task of summarization. Every text or \n",
    "sentence can be thought of as sequential data as the order of words is essential for the \n",
    "natural language interpretation and formation. In order to process sequential data, which \n",
    "is the case for most NLP problems, the architecture needs to retain information with the \n",
    "help of some memory.  \n",
    "One of the variants of RNN [7, 8] the LSTM network [9], retains sequential \n",
    "information with the help of connected nodes by keeping relevant information and \n",
    "forgetting insignificant information that helped in generating summaries. This \n",
    "methodology of LSTM network [9] was utilized to develop the encoder-decoder model \n",
    "[9]. Seq2seq models implemented with the help of the encoder-decoder framework for \n",
    "solving NLP tasks gave wonderful results, but there was still the issue of parallelization. \n",
    "Even though the sequential information is retained in the case of the encoder-decoder \n",
    "model [10] , the processing, in this case, is done by taking one input at a time as LSTM \n",
    "[8] takes only a single input at a time. This is a problematic situation as even though \n",
    "this model gives improved results, it proves to be unsuccessful for every possible case \n",
    "and defeats the purpose of creating machine perception.  \n",
    "This led to the addition of the Attention layer [8]. As depicted in Figure 1 [10], an \n",
    "attention layer in the encoder-decoder model [10] analyses the input sequence at every \n",
    "step, and based on the previous sequences, assigns a weight to it. The attention layer \n",
    "[11] creates vector matrices by considering every word in the sentence for one input. \n",
    "Hence, the attention layer forces the machine to look over the entire text as one input \n",
    "rather than separate sequences as separate inputs. This mechanism was extremely \n",
    "effective [11] for the abstractive approach and became popular. For this work, we have \n",
    "utilized the transformer architecture [11], developed by Google as a baseline model. \n",
    "Fig. 1. Attention mechanism in Encoder-Decoder architecture [10] \n",
    "The introduction of several pre-trained language models, for example, BERT [12], \n",
    "PEGASUS [13], UNiLM [14], GPT [15], etc., has transformed the field of NLP and \n",
    "their great results encouraged us to employ these technologies for the task of \n",
    "summarization. Most of the pre-trained models used in this project are based on \n",
    "Google’s powerful Transformer architecture [11] that was developed in 2017. It is \n",
    "similar to RNN and is inspired from the encoder-decoder framework.  Transformer \n",
    "model [11] was invented to solve natural language processing tasks that involved \n",
    "transforming an input sequence into an output sequence. These pre-trained language \n",
    "models from Hugging face library [16] can be used to solve multiple NLP problems. \n",
    "3   Methodology \n",
    "3.1 Dataset \n",
    "From this section onwards, we will outline our basic experimental setup, discuss the \n",
    "evaluation metrics, and then describe various models that we used for our study. Then \n",
    "we will combine insights from our study and show the comparative performance of the \n",
    "models. The dataset we used was generated from a dataset used for text classification. \n",
    "It consists of 2225 BBC news website documents relating to stories used in the paper \n",
    "[17] in five topical areas from 2004-2005, all of whose rights, including copyright, are \n",
    "held by the BBC in the content of the original papers.           \n",
    "3.2   Preprocessing \n",
    "This dataset consists of long news articles along with short summaries for comparison. \n",
    "The raw dataset was then cleaned using various pre-processing techniques such as: \n",
    "Lower casing - To convert the input text into the same casing format so that all capital, \n",
    "lower case and mixed case are treated similarly. \n",
    "Eliminate Punctuation - HTML tags and links- Removal of punctuations, links and \n",
    "tags that do not add meaning to the text such as “!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_{|}~`” \n",
    "to standardise the text. \n",
    "Eliminate Stopwords and frequently occurring words - Removal of common words \n",
    "such as ‘the’, ‘a’, etc that are frequently used in a text but do not provide valuable \n",
    "information for downstream analysis. \n",
    "Stemming - Reducing the inflected words to their root form. \n",
    "Lemmatization - Reducing derived words to their base or root form while making sure \n",
    "that root words belong to the language. \n",
    "Contraction mapping - Expanding the shortened version of words or syllables. \n",
    "2.3   Model Explanation \n",
    "Basic Understanding of Transformer model -The transformer network [11] is solely \n",
    "based upon multiple attention layers. It does not make use of RNN and is reliant on \n",
    "attention layers and positional encoding for remembering the sequence of words in the \n",
    "input sequence. The global dependencies created with the help of multiple attention \n",
    "layers help in creating parallelization in processing the input.  \n",
    "The transformer model [11] contains encoder and decoder layers, where each is \n",
    "connected to a multi-head attention layer and feed forward network layers. The model \n",
    "remembers the position and sequence of words with the help of cosine and sine \n",
    "functions that creates positional encoding. The multi-head attention layer [11] in the \n",
    "encoder and decoder layer applies a mechanism called self-attention. The input is fed \n",
    "into three connected layers to create query (Q), key (K), and value (V) vectors [11]. \n",
    "It contains an \n",
    "encoder and decoder layer and the various normalization and multi-head \n",
    "attention layers are also depicted in the figure. \n",
    "Fig. 2. Transformer Model Architecture [11] \n",
    "Pretrained Models based on Transformers - Hugging face [16] works as an open\n",
    "source for providing many useful NLP libraries and datasets. Its most famous library is \n",
    "the Transformer library. The transformer library consists of various pre-trained models \n",
    "to predict summaries of texts that can be fine-tuned for any dataset. Here we will be \n",
    "discussing some pre-trained models that were tuned and implemented for the BBC news \n",
    "dataset to give fairly good summaries. The models we used are as follows: \n",
    "Pipeline – The pipelines are a great and quick way to use different pre-trained models \n",
    "for inference. These pipelines are objects that abstract most of the library's complicated \n",
    "code, offering a simple API dedicated to several tasks, including text summarization. \n",
    "Pipelines enclose the overall steps of every NLP process such as Tokenization, \n",
    "Inference, which maps every token into a more meaningful representation, and \n",
    "Decoding. The Hugging Face transformers summarization pipeline has made the task \n",
    "easier, faster and more efficient to execute in English language. We used the machine \n",
    "learning model that has been trained on the CNN news corpus by using a fine-tuned \n",
    "BART algorithm [18] and is loaded from pipeline() using the task identifier: \n",
    "\"summarization\".  \n",
    "BART – BART stands for Bidirectional and Auto Regressive Transformers [18]. It is \n",
    "built with a seq2seq model trained with denoising as a pre-training purpose. It uses a \n",
    "standard seq2seq model architecture combining an encoder similar to BERT [12] and a \n",
    "GPT-like decoder [15]. The pre-training task involves changing the order of the original \n",
    "phrases randomly and a new scheme where text ranges are switched with a single mask \n",
    "token. The large model of BART [18] consists of twice as many layers as are present \n",
    "in the base model. It is quite similar to the BERT [12] model but BART contains about \n",
    "10% more features than the BERT model of comparable size. BART's decoder is \n",
    "autoregressive, and it is regulated for generating sequential NLP tasks such as text \n",
    "summarization. The data is taken from the input but changed, which is closely related \n",
    "to the denoising pre-training objective. Hence, the input sequence embedding is the \n",
    "input of the encoder, and the decoder autoregressively produces output. We have used \n",
    "the \"facebook/bart-large-cnn\" pre-trained model and then the Bart tokenizer, which is \n",
    "constructed from the GPT-2 tokenizer. Hence words are encoded differently depending \n",
    "on their position in the sentence. \n",
    "T5 - T5 is the abbreviation for \"Text-to-Text Transfer Transformer\" [19]. The idea \n",
    "behind the T5 model is transfer learning [20]. The model was initially trained on a task \n",
    "containing large text in Transfer Learning before it was finely tuned on a downstream \n",
    "task so that the model learns general-purpose skills and information to be applied to \n",
    "tasks such as summarization T5 [19] uses a sequence-to-sequence generation method \n",
    "that feeds the encoded input via cross-attention layers to the decoder and generates the \n",
    "decoder output autoregressive. We have fine-tuned a T5 model [19], where the encoder \n",
    "takes an input a series of tokens which are mapped to a sequence of embeddings. A \n",
    "block containing two subcomponents are present in the encoder block namely, a self\n",
    "attention layer and feed forward network. The decoder and encoder are similar in \n",
    "structure, except that there's a generalized attention mechanism after every self\n",
    "attention layer. This allows the model to operate only on the previous outputs. The final \n",
    "decoder block produces an output which is fed into another layer. This final layer is a \n",
    "dense layer where the activation function is softmax. The weights from the output of \n",
    "this layer are fed into the input embedding matrix. \n",
    "PEGASUS - PEGASUS stands for Pre-training with Extracted Gap-sentences for \n",
    "Abstractive Summarization Sequence-to-sequence models [13]. In this model, \n",
    "significant lines are eliminated from the input text and are compiled as separate outputs. \n",
    "Also, choosing only relevant sentences outperforms the randomly selected sentences. \n",
    "This methodology is preferred for abstractive summarization as it is similar to the task \n",
    "of interpreting the entire document and generating a summary. It is used to train a \n",
    "Transformer model on a text data resulting in the PEGASUS model. The model is pre\n",
    "trained on CNN/DailyMail summarization datasets. \n",
    "Fig. 3. The PEGASUS Model Architecture \n",
    "As shown in Figure 3 [13], it was found that it works as a prior-training aim for text \n",
    "summarization to mask complete sentences from the text and create gap-sentences from \n",
    "the remaining document.     \n",
    "4   Results \n",
    "4.1 Qualitative Analysis \n",
    "For generating summaries, we fine-tuned the following transformer-based pre-trained \n",
    "language models from the Hugging face library [16]. The BBC News Dataset was used \n",
    "for generating summaries that consisted of text and human generated summaries which \n",
    "are summaries that have been written by humans. \n",
    "We used the human generated summaries to perform a comprehensive analysis of \n",
    "the summaries generated by different models. Table 1 gives the results obtained from \n",
    "different models which have been compared with the given reference summary - “An \n",
    "incident of robbery that occurred at the shopping complex last night was reported at \n",
    "the local police station this morning. A lot of valuables were stolen and multiple such \n",
    "robberies have been reported in that area. The people have been asked to stay alert and \n",
    "notice any suspicious activity. A CCTV camera from a nearby house captured the \n",
    "incident and there were a total four robbers who can be seen carrying bags. The \n",
    "shopkeeper suffered a loss and hopes the police catch the culprits.”.'''\n",
    "new_summary = summarize(article)\n",
    "print(new_summary)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 24984,
     "sourceId": 32267,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30559,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10316.334349,
   "end_time": "2024-04-18T20:18:16.300862",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-18T17:26:19.966513",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "116be48eec3949e9b1c75e8af531f001": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_67c71cf1ab45498789ab42762d402cc3",
       "placeholder": "​",
       "style": "IPY_MODEL_2a42ea91d7804e478ccecaebfe06278a",
       "value": " 792k/792k [00:00&lt;00:00, 998kB/s]"
      }
     },
     "162a3c31130246ff93ca7d7323ba87c5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "1b05807724a34730ad2bfe5708a72d77": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2679c728507841f8942d5fa375f6ec1b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "2a293c1ef3eb426cb129366cdc178d4f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_998b91f08abc4a7f8fd33902da9f31b0",
       "max": 147,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_162a3c31130246ff93ca7d7323ba87c5",
       "value": 147
      }
     },
     "2a42ea91d7804e478ccecaebfe06278a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "31bb444e58c94558b9dcbccc7510fa04": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3ae5d13f83e64c7e98029e0c903b5afd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d1052c0afdc9473db37ddba2efba9469",
       "max": 1208,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2679c728507841f8942d5fa375f6ec1b",
       "value": 1208
      }
     },
     "3c829a4e95d442c69da0f86207e4a65c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "40b93764c6b44435b29a458354eaf754": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_31bb444e58c94558b9dcbccc7510fa04",
       "placeholder": "​",
       "style": "IPY_MODEL_d0bdaa235e854296a65a2472a4b47f0f",
       "value": " 1.21k/1.21k [00:00&lt;00:00, 107kB/s]"
      }
     },
     "46593a90f655424286778e0e7559f21d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4a6761e32e454498b166ace26c8c241a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_56ab06cff58d4a99bcc9311b6eb0d9a3",
        "IPY_MODEL_7721573a01484449918ac8b68a2b7cf5",
        "IPY_MODEL_dee3268eb12a4e3d82f52a70b1dd6d62"
       ],
       "layout": "IPY_MODEL_a14e81527cb64a3197e8cc0a431dc1f3"
      }
     },
     "4dcd14652ad74d5ba5b43008d463fc5f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "56ab06cff58d4a99bcc9311b6eb0d9a3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d9f09159a41c43fbb916bdaa46f3628e",
       "placeholder": "​",
       "style": "IPY_MODEL_4dcd14652ad74d5ba5b43008d463fc5f",
       "value": "Downloading model.safetensors: 100%"
      }
     },
     "576d665d7cd741598cf66b30c01be30f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b07eb82fcf1e4f8f8a2fabed33260e99",
       "placeholder": "​",
       "style": "IPY_MODEL_66b17d1f5c1e46c9a800c4726c6407c0",
       "value": "Downloading generation_config.json: 100%"
      }
     },
     "58e58cdf1d6b488b943b2b3d8cacceea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cf1a0a614b604c75935766690869d674",
       "max": 791656,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c0627979321640e294e5d24d42f1c8b0",
       "value": 791656
      }
     },
     "5b6e303132474f56b00810366878fa8c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5f315479e9914e088524a3dd3c6a3066": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d29ce240bc48440bbb2f46b5d375a523",
       "placeholder": "​",
       "style": "IPY_MODEL_f1aec5ca183246bd935ed7e7feaed391",
       "value": " 147/147 [00:00&lt;00:00, 13.0kB/s]"
      }
     },
     "66b17d1f5c1e46c9a800c4726c6407c0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "67c71cf1ab45498789ab42762d402cc3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6a6af4c3b8604d088d28d0e9ea0ecdd3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7721573a01484449918ac8b68a2b7cf5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b502bd49c2a14c199b47a55037dac395",
       "max": 891646390,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c7a5773219544f2e8fc4e926e7fd9ba6",
       "value": 891646390
      }
     },
     "923726df53624beead0a694b453faee6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "998b91f08abc4a7f8fd33902da9f31b0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a058b9f135204ddca4f6a0911db7688b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d20d57752ed34764a455612e0a329ddb",
        "IPY_MODEL_3ae5d13f83e64c7e98029e0c903b5afd",
        "IPY_MODEL_40b93764c6b44435b29a458354eaf754"
       ],
       "layout": "IPY_MODEL_923726df53624beead0a694b453faee6"
      }
     },
     "a14e81527cb64a3197e8cc0a431dc1f3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a360ef611f8c4064908257088cab3a4a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a4d3d117513346f1be263e4536d479ab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ad12904181974c68866aeff9797c8bb1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_576d665d7cd741598cf66b30c01be30f",
        "IPY_MODEL_2a293c1ef3eb426cb129366cdc178d4f",
        "IPY_MODEL_5f315479e9914e088524a3dd3c6a3066"
       ],
       "layout": "IPY_MODEL_6a6af4c3b8604d088d28d0e9ea0ecdd3"
      }
     },
     "af0aa210c7304b6d90e883a06747ba21": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b07eb82fcf1e4f8f8a2fabed33260e99": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b502bd49c2a14c199b47a55037dac395": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c0627979321640e294e5d24d42f1c8b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c76d7dbc2223401db6f7cb69f5e87bfe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c773e5e16a884567bf3300631664eafe",
        "IPY_MODEL_58e58cdf1d6b488b943b2b3d8cacceea",
        "IPY_MODEL_116be48eec3949e9b1c75e8af531f001"
       ],
       "layout": "IPY_MODEL_af0aa210c7304b6d90e883a06747ba21"
      }
     },
     "c773e5e16a884567bf3300631664eafe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1b05807724a34730ad2bfe5708a72d77",
       "placeholder": "​",
       "style": "IPY_MODEL_a360ef611f8c4064908257088cab3a4a",
       "value": "Downloading spiece.model: 100%"
      }
     },
     "c7a5773219544f2e8fc4e926e7fd9ba6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "cf1a0a614b604c75935766690869d674": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d0bdaa235e854296a65a2472a4b47f0f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d1052c0afdc9473db37ddba2efba9469": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d20d57752ed34764a455612e0a329ddb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5b6e303132474f56b00810366878fa8c",
       "placeholder": "​",
       "style": "IPY_MODEL_46593a90f655424286778e0e7559f21d",
       "value": "Downloading config.json: 100%"
      }
     },
     "d29ce240bc48440bbb2f46b5d375a523": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d9f09159a41c43fbb916bdaa46f3628e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dee3268eb12a4e3d82f52a70b1dd6d62": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3c829a4e95d442c69da0f86207e4a65c",
       "placeholder": "​",
       "style": "IPY_MODEL_a4d3d117513346f1be263e4536d479ab",
       "value": " 892M/892M [00:46&lt;00:00, 20.6MB/s]"
      }
     },
     "f1aec5ca183246bd935ed7e7feaed391": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
