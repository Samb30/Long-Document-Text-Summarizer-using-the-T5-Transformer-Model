# Long Document Text Summarizer using the T5 Transformer Model

This project implements an **abstractive text summarization** system for long documents using the **T5 (Text-To-Text Transfer Transformer)** model. It is designed to handle lengthy documents such as research papers and articles, providing comprehensive and coherent summaries while preserving key information.

---

## âœ¨ Features

- âœ… Efficient processing of long documents (e.g., research papers, articles)
- âœ… Abstractive summarization capability
- âœ… Fine-tuned T5 transformer model (`LD-T5`)
- âœ… Higher ROUGE scores compared to baseline models
- âœ… Support for various document formats, including PDFs
- âœ… User-friendly interface built with **Streamlit**

---

## ðŸ§  Model Architecture

The project utilizes the **T5-base** model with an **encoder-decoder** structure:

- **Encoder:** Processes the input document and creates contextual representations
- **Decoder:** Generates the summary based on the encoded representations
- **Multi-head Self-Attention:** Enables the model to consider multiple perspectives and capture long-range dependencies

## Screenshots

![Homepage](https://github.com/user-attachments/assets/699c60bd-90af-4abf-b3fb-b7334f1ec217)
![Summary Generation](https://github.com/user-attachments/assets/d70d3e0f-9121-4ec2-a7a5-5d0f69612fe9)
![Generated Summary](https://github.com/user-attachments/assets/a442a37d-4141-4968-bb2d-a9f1771258bf)


